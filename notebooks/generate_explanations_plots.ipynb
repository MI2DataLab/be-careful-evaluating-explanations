{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from metrics.heatmaps import (\n",
    "    calculate_relevance_mass_accuracy,\n",
    "    calculate_relevance_rank_accuracy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"Enlarged Cardiomediastinum\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Lung Opacity\",\n",
    "    \"Lung Lesion\",\n",
    "    \"Edema\",\n",
    "    \"Consolidation\",\n",
    "    \"Atelectasis\",\n",
    "    \"Pneumothorax\",\n",
    "    \"Pleural Effusion\",\n",
    "]\n",
    "xai_methods = [\"integrated_gradients\", \"gradient\", \"lrp\", \"smoothgrad\"]\n",
    "training_types = [\"pretrained\", \"from_scratch\"]\n",
    "models = [\"vit\", \"swinvit\", \"densenet\"]\n",
    "save_folder = Path(\"../results\")\n",
    "dataset_folder = Path(\"../dataset/chexlocalize/CheXpert/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list((dataset_folder / \"val\").glob(\"*/*/view1_frontal*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_images_to_plot = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_plot = list(random.sample(images, k=number_of_images_to_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_plot = list(random.sample(images, k=number_of_images_to_plot))\n",
    "masks_to_plot = [\n",
    "    random.choice(list(image.parent.glob(\"view1_frontal*.npy\")))\n",
    "    for image in images_to_plot\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(masks_to_plot[0].name.split(\"_\")[2:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = ListedColormap([\"#FFFFFF00\", \"yellow\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(2, number_of_images_to_plot // 2, figsize=(15, 10))\n",
    "for num, (i, j) in enumerate(\n",
    "    product(\n",
    "        range(2),\n",
    "        range(number_of_images_to_plot // 2),\n",
    "    )\n",
    "):\n",
    "    img = plt.imread(images_to_plot[num])\n",
    "    mask = np.load(masks_to_plot[num])\n",
    "    ax[i, j].imshow(img, cmap=\"gray\")\n",
    "    ax[i, j].imshow(mask, cmap=cmap, alpha=0.3)\n",
    "    ax[i, j].axis(\"off\")\n",
    "    ax[i, j].set_title(\n",
    "        \" \".join(masks_to_plot[num].name.split(\"_\")[2:-1]),\n",
    "        loc=\"center\",\n",
    "        y=-0.1,\n",
    "    )\n",
    "plt.savefig(\n",
    "    \"example_images.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.imshow(\n",
    "    mask_ == 1,\n",
    "    cmap=ListedColormap([\"black\", \"green\"]),\n",
    "    alpha=0.5,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_float(x):\n",
    "    return float(x.replace(\"tensor(\", \"\").replace(\")\", \"\"))\n",
    "\n",
    "\n",
    "def plot_heatmap(\n",
    "    save_folder,\n",
    "    dataset_folder,\n",
    "    model,\n",
    "    training_type,\n",
    "    class_name,\n",
    "    xai_method,\n",
    "    images_save_folder=Path(\"images\"),\n",
    "    selected_patient=None,\n",
    "):\n",
    "    inverse_path = (\n",
    "        save_folder\n",
    "        / f\"finetuned_{model}\"\n",
    "        / training_type\n",
    "        / \"inverse_mask\"\n",
    "        / f\"_{class_name}_{xai_method}_output.csv\"\n",
    "    )\n",
    "    normal_path = (\n",
    "        save_folder\n",
    "        / f\"finetuned_{model}\"\n",
    "        / training_type\n",
    "        / \"normal_mask\"\n",
    "        / f\"_{class_name}_{xai_method}_output.csv\"\n",
    "    )\n",
    "    inverse_data = pd.read_csv(inverse_path)\n",
    "    normal_data = pd.read_csv(normal_path)\n",
    "    inverse_data.mass_accuracy = inverse_data.mass_accuracy.apply(\n",
    "        tensor_to_float\n",
    "    )\n",
    "    normal_data.mass_accuracy = normal_data.mass_accuracy.apply(\n",
    "        tensor_to_float\n",
    "    )\n",
    "    inverse_data.rank_accuracy = inverse_data.rank_accuracy.apply(\n",
    "        tensor_to_float\n",
    "    )\n",
    "    normal_data.rank_accuracy = normal_data.rank_accuracy.apply(\n",
    "        tensor_to_float\n",
    "    )\n",
    "\n",
    "    normal_data.sort_values(by=\"mass_accuracy\", inplace=True)\n",
    "    inverse_data.sort_values(by=\"mass_accuracy\", inplace=True)\n",
    "    if selected_patient is not None:\n",
    "        best_mass_patient = selected_patient\n",
    "    else:\n",
    "        best_mass_patient = normal_data.iloc[-1].path\n",
    "    inverse_data.set_index(\"path\", inplace=True)\n",
    "    normal_data.set_index(\"path\", inplace=True)\n",
    "    image = plt.imread(dataset_folder / best_mass_patient)\n",
    "    gt_mask = np.load(\n",
    "        dataset_folder\n",
    "        / best_mass_patient.replace(\n",
    "            \".jpg\", f\"_{class_name.replace(' ', '_')}_mask.npy\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    positive_heatmap = np.load(\n",
    "        normal_path.parent\n",
    "        / best_mass_patient.replace(\n",
    "            \".jpg\", f\"{class_name}_{xai_method}_relevance.npy\"\n",
    "        )\n",
    "    )\n",
    "    positive_heatmap = (\n",
    "        torch.nn.functional.interpolate(\n",
    "            torch.tensor(positive_heatmap), size=image.shape, mode=\"bilinear\"\n",
    "        )\n",
    "        .detach()\n",
    "        .numpy()[0]\n",
    "    )\n",
    "    negative_heatmap = np.load(\n",
    "        inverse_path.parent\n",
    "        / best_mass_patient.replace(\n",
    "            \".jpg\", f\"{class_name}_{xai_method}_relevance.npy\"\n",
    "        )\n",
    "    )\n",
    "    negative_heatmap = (\n",
    "        torch.nn.functional.interpolate(\n",
    "            torch.tensor(negative_heatmap), size=image.shape, mode=\"bilinear\"\n",
    "        )\n",
    "        .detach()\n",
    "        .numpy()[0]\n",
    "    )\n",
    "    normal_heatmap = np.load(\n",
    "        save_folder\n",
    "        / f\"{model}\"\n",
    "        / training_type\n",
    "        / best_mass_patient.replace(\n",
    "            \".jpg\", f\"{class_name}_{xai_method}_relevance.npy\"\n",
    "        )\n",
    "    )\n",
    "    normal_heatmap = (\n",
    "        torch.nn.functional.interpolate(\n",
    "            torch.tensor(normal_heatmap), size=image.shape, mode=\"bilinear\"\n",
    "        )\n",
    "        .detach()\n",
    "        .numpy()[0]\n",
    "    )\n",
    "    positive_heatmap = np.maximum(positive_heatmap, 0).sum(axis=0)\n",
    "    positive_heatmap = (positive_heatmap - positive_heatmap.min()) / (\n",
    "        positive_heatmap.max() - positive_heatmap.min()\n",
    "    )\n",
    "    negative_heatmap = np.maximum(negative_heatmap, 0).sum(axis=0)\n",
    "    negative_heatmap = (negative_heatmap - negative_heatmap.min()) / (\n",
    "        negative_heatmap.max() - negative_heatmap.min()\n",
    "    )\n",
    "    normal_heatmap = np.maximum(normal_heatmap, 0).sum(axis=0)\n",
    "    normal_heatmap = (normal_heatmap - normal_heatmap.min()) / (\n",
    "        normal_heatmap.max() - normal_heatmap.min()\n",
    "    )\n",
    "    positive_mass_accuracy = calculate_relevance_mass_accuracy(\n",
    "        torch.tensor(positive_heatmap), torch.tensor(gt_mask)\n",
    "    )\n",
    "    negative_mass_accuracy = calculate_relevance_mass_accuracy(\n",
    "        torch.tensor(negative_heatmap), torch.tensor(gt_mask)\n",
    "    )\n",
    "    normal_mass_accuracy = calculate_relevance_mass_accuracy(\n",
    "        torch.tensor(normal_heatmap), torch.tensor(gt_mask)\n",
    "    )\n",
    "    positive_rank_accuracy = calculate_relevance_rank_accuracy(\n",
    "        torch.tensor(positive_heatmap), torch.tensor(gt_mask)\n",
    "    )\n",
    "    negative_rank_accuracy = calculate_relevance_rank_accuracy(\n",
    "        torch.tensor(negative_heatmap), torch.tensor(gt_mask)\n",
    "    )\n",
    "    normal_rank_accuracy = calculate_relevance_rank_accuracy(\n",
    "        torch.tensor(normal_heatmap), torch.tensor(gt_mask)\n",
    "    )\n",
    "\n",
    "    accuracies = {\n",
    "        f\"{training_type}_{model}_{class_name}_{xai_method}\": {\n",
    "            \"positive\": {\n",
    "                \"mass_accuracy\": positive_mass_accuracy,\n",
    "                \"rank_accuracy\": positive_rank_accuracy,\n",
    "            },\n",
    "            \"negative\": {\n",
    "                \"mass_accuracy\": negative_mass_accuracy,\n",
    "                \"rank_accuracy\": negative_rank_accuracy,\n",
    "            },\n",
    "            \"normal\": {\n",
    "                \"mass_accuracy\": normal_mass_accuracy,\n",
    "                \"rank_accuracy\": normal_rank_accuracy,\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(positive_heatmap, alpha=0.3, cmap=\"jet\", vmin=0, vmax=1)\n",
    "    plt.imshow(gt_mask, alpha=0.3, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder\n",
    "        / f\"aligned_heatmap_{training_type}_{model}_{class_name}_{xai_method}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(normal_heatmap, alpha=0.3, cmap=\"jet\", vmin=0, vmax=1)\n",
    "    plt.imshow(gt_mask, alpha=0.3, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder\n",
    "        / f\"normal_heatmap_{training_type}_{model}_{class_name}_{xai_method}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(negative_heatmap, alpha=0.3, cmap=\"jet\", vmin=0, vmax=1)\n",
    "    plt.imshow(gt_mask, alpha=0.3, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder\n",
    "        / f\"misaligned_heatmap_{training_type}_{model}_{class_name}_{xai_method}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    _, ax = plt.subplots(3, 1, figsize=(15, 10))\n",
    "    ax[0].imshow(image, cmap=\"gray\")\n",
    "    ax[0].imshow(positive_heatmap, alpha=0.3, cmap=\"jet\", vmin=0, vmax=1)\n",
    "    ax[0].imshow(gt_mask, alpha=0.3, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Aligned\")\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[1].imshow(image, cmap=\"gray\")\n",
    "    ax[1].imshow(normal_heatmap, alpha=0.3, cmap=\"jet\", vmin=0, vmax=1)\n",
    "    ax[1].imshow(gt_mask, alpha=0.3, cmap=\"gray\")\n",
    "    ax[1].set_title(\"Normal\")\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[2].imshow(image, cmap=\"gray\")\n",
    "    ax[2].imshow(negative_heatmap, alpha=0.3, cmap=\"jet\", vmin=0, vmax=1)\n",
    "    ax[2].imshow(gt_mask, alpha=0.3, cmap=\"gray\")\n",
    "    ax[2].set_title(\"Misaligned\")\n",
    "    ax[2].axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder\n",
    "        / f\"positive_normal_negative_heatmap_{training_type}_{model}_{class_name}_{xai_method}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    if selected_patient is None:\n",
    "        return best_mass_patient, accuracies\n",
    "    return accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def generate_plot(args):\n",
    "    class_name, xai_method, training_type, model = args\n",
    "    _, acc = plot_heatmap(\n",
    "        save_folder,\n",
    "        dataset_folder,\n",
    "        model,\n",
    "        training_type,\n",
    "        class_name,\n",
    "        xai_method,\n",
    "    )\n",
    "    return acc\n",
    "\n",
    "\n",
    "args_list = list(product(classes, xai_methods, training_types, models))\n",
    "\n",
    "\n",
    "def create_plots():\n",
    "    with Pool(8) as p:\n",
    "        accs = list(\n",
    "            tqdm(p.imap(generate_plot, args_list), total=len(args_list))\n",
    "        )\n",
    "    return accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = create_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "accuracies = {}\n",
    "for class_name, xai_method, training_type, model in tqdm(\n",
    "    product(classes, xai_methods, training_types, models),\n",
    "    total=len(classes) * len(xai_methods) * len(training_types) * len(models),\n",
    "):\n",
    "    _, acc = plot_heatmap(\n",
    "        save_folder,\n",
    "        dataset_folder,\n",
    "        model,\n",
    "        training_type,\n",
    "        class_name,\n",
    "        xai_method,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT + IG example attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_data = pd.read_csv(\"../results/metrics_diff_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = \"vit\"\n",
    "selected_attribution = \"integrated_gradients\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_data = diff_data[\n",
    "    (diff_data.model == selected_model)\n",
    "    & (diff_data.xai_method == selected_attribution)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(\n",
    "    save_folder,\n",
    "    model,\n",
    "    training_type,\n",
    "    class_name,\n",
    "    xai_method,\n",
    "    patient_path,\n",
    "    mask_alpha=0.5,\n",
    "    attribution_alpha=0.5,\n",
    "    attribution_cmap=\"jet\",\n",
    "    mask_cmap=\"gray\",\n",
    "    na_attribution_threshold=0.01,\n",
    "    images_save_folder=\"images\",\n",
    "):\n",
    "    inverse_path = (\n",
    "        save_folder\n",
    "        / f\"finetuned_{model}\"\n",
    "        / training_type\n",
    "        / \"inverse_mask\"\n",
    "        / f\"_{class_name}_{xai_method}_output.csv\"\n",
    "    )\n",
    "    normal_path = (\n",
    "        save_folder\n",
    "        / f\"finetuned_{model}\"\n",
    "        / training_type\n",
    "        / \"normal_mask\"\n",
    "        / f\"_{class_name}_{xai_method}_output.csv\"\n",
    "    )\n",
    "\n",
    "    image = plt.imread(dataset_folder / patient_path)\n",
    "    gt_mask = np.load(\n",
    "        dataset_folder\n",
    "        / patient_path.replace(\n",
    "            \".jpg\", f\"_{class_name.replace(' ', '_')}_mask.npy\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    positive_heatmap = np.load(\n",
    "        normal_path.parent\n",
    "        / patient_path.replace(\n",
    "            \".jpg\", f\"{class_name}_{xai_method}_relevance.npy\"\n",
    "        )\n",
    "    )\n",
    "    positive_heatmap = (\n",
    "        torch.nn.functional.interpolate(\n",
    "            torch.tensor(positive_heatmap), size=image.shape, mode=\"bilinear\"\n",
    "        )\n",
    "        .detach()\n",
    "        .numpy()[0]\n",
    "    )\n",
    "    negative_heatmap = np.load(\n",
    "        inverse_path.parent\n",
    "        / patient_path.replace(\n",
    "            \".jpg\", f\"{class_name}_{xai_method}_relevance.npy\"\n",
    "        )\n",
    "    )\n",
    "    negative_heatmap = (\n",
    "        torch.nn.functional.interpolate(\n",
    "            torch.tensor(negative_heatmap), size=image.shape, mode=\"bilinear\"\n",
    "        )\n",
    "        .detach()\n",
    "        .numpy()[0]\n",
    "    )\n",
    "    normal_heatmap = np.load(\n",
    "        save_folder\n",
    "        / f\"{model}\"\n",
    "        / training_type\n",
    "        / patient_path.replace(\n",
    "            \".jpg\", f\"{class_name}_{xai_method}_relevance.npy\"\n",
    "        )\n",
    "    )\n",
    "    normal_heatmap = (\n",
    "        torch.nn.functional.interpolate(\n",
    "            torch.tensor(normal_heatmap), size=image.shape, mode=\"bilinear\"\n",
    "        )\n",
    "        .detach()\n",
    "        .numpy()[0]\n",
    "    )\n",
    "    positive_heatmap = np.maximum(positive_heatmap, 0).sum(axis=0)\n",
    "    positive_heatmap = (positive_heatmap - positive_heatmap.min()) / (\n",
    "        positive_heatmap.max() - positive_heatmap.min()\n",
    "    )\n",
    "    negative_heatmap = np.maximum(negative_heatmap, 0).sum(axis=0)\n",
    "    negative_heatmap = (negative_heatmap - negative_heatmap.min()) / (\n",
    "        negative_heatmap.max() - negative_heatmap.min()\n",
    "    )\n",
    "    normal_heatmap = np.maximum(normal_heatmap, 0).sum(axis=0)\n",
    "    normal_heatmap = (normal_heatmap - normal_heatmap.min()) / (\n",
    "        normal_heatmap.max() - normal_heatmap.min()\n",
    "    )\n",
    "    if na_attribution_threshold:\n",
    "        positive_heatmap = np.where(\n",
    "            positive_heatmap < na_attribution_threshold, -1, positive_heatmap\n",
    "        )\n",
    "        negative_heatmap = np.where(\n",
    "            negative_heatmap < na_attribution_threshold, -1, negative_heatmap\n",
    "        )\n",
    "        normal_heatmap = np.where(\n",
    "            normal_heatmap < na_attribution_threshold, -1, normal_heatmap\n",
    "        )\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(\n",
    "        positive_heatmap,\n",
    "        alpha=attribution_alpha,\n",
    "        cmap=attribution_cmap,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    plt.imshow(gt_mask, alpha=mask_alpha, cmap=mask_cmap)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder\n",
    "        / f\"aligned_heatmap_{training_type}_{model}_{class_name}_{xai_method}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(\n",
    "        positive_heatmap,\n",
    "        alpha=attribution_alpha,\n",
    "        cmap=attribution_cmap,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder\n",
    "        / f\"aligned_heatmap_{training_type}_{model}_{class_name}_{xai_method}_without_mask.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(gt_mask, alpha=mask_alpha, cmap=mask_cmap)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder / f\"gt_mask.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(\n",
    "        negative_heatmap,\n",
    "        alpha=attribution_alpha,\n",
    "        cmap=attribution_cmap,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    plt.imshow(gt_mask, alpha=mask_alpha, cmap=mask_cmap)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder\n",
    "        / f\"misaligned_heatmap_{training_type}_{model}_{class_name}_{xai_method}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(\n",
    "        negative_heatmap,\n",
    "        alpha=attribution_alpha,\n",
    "        cmap=attribution_cmap,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder\n",
    "        / f\"misaligned_heatmap_{training_type}_{model}_{class_name}_{xai_method}_without_mask.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribution_cmap = plt.cm.jet.copy()\n",
    "attribution_cmap = sns.light_palette(\"red\", as_cmap=True)\n",
    "attribution_cmap.set_under(color=\"#FFFFFF00\")\n",
    "mask_cmap = ListedColormap([\"#FFFFFF00\", \"yellow\"])\n",
    "attribution_cmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = Path(\"../results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = [\n",
    "    571,\n",
    "    994,\n",
    "    758,\n",
    "]\n",
    "patients_name = [\n",
    "    \"upper_right\",\n",
    "    \"middle\",\n",
    "    \"lower_left\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient, patient_name in zip(patients, patients_name):\n",
    "    cur_data = diff_data.iloc[patient]\n",
    "    plot_heatmap(\n",
    "        save_folder,\n",
    "        selected_model,\n",
    "        cur_data.pretraining,\n",
    "        cur_data.label,\n",
    "        selected_attribution,\n",
    "        patient_path=cur_data.path,\n",
    "        attribution_cmap=attribution_cmap,\n",
    "        mask_cmap=mask_cmap,\n",
    "        na_attribution_threshold=0.1,\n",
    "        mask_alpha=0.3,\n",
    "        images_save_folder=Path(f\"vit_ig/{patient_name}\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binary_heatmap(\n",
    "    save_folder,\n",
    "    model,\n",
    "    training_type,\n",
    "    class_name,\n",
    "    xai_method,\n",
    "    patient_path,\n",
    "    mask_alpha=0.5,\n",
    "    attribution_alpha=0.5,\n",
    "    attribution_cmap=\"jet\",\n",
    "    mask_cmap=\"gray\",\n",
    "    na_attribution_threshold=0.01,\n",
    "    images_save_folder=\"images\",\n",
    "):\n",
    "    inverse_path = (\n",
    "        save_folder\n",
    "        / f\"finetuned_{model}\"\n",
    "        / training_type\n",
    "        / \"inverse_mask\"\n",
    "        / f\"_{class_name}_{xai_method}_output.csv\"\n",
    "    )\n",
    "    normal_path = (\n",
    "        save_folder\n",
    "        / f\"finetuned_{model}\"\n",
    "        / training_type\n",
    "        / \"normal_mask\"\n",
    "        / f\"_{class_name}_{xai_method}_output.csv\"\n",
    "    )\n",
    "\n",
    "    image = plt.imread(dataset_folder / patient_path)\n",
    "    gt_mask = np.load(\n",
    "        dataset_folder\n",
    "        / patient_path.replace(\n",
    "            \".jpg\", f\"_{class_name.replace(' ', '_')}_mask.npy\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    positive_heatmap = np.load(\n",
    "        normal_path.parent\n",
    "        / patient_path.replace(\n",
    "            \".jpg\", f\"{class_name}_{xai_method}_relevance.npy\"\n",
    "        )\n",
    "    )\n",
    "    positive_heatmap = (\n",
    "        torch.nn.functional.interpolate(\n",
    "            torch.tensor(positive_heatmap), size=image.shape, mode=\"bilinear\"\n",
    "        )\n",
    "        .detach()\n",
    "        .numpy()[0]\n",
    "    )\n",
    "    negative_heatmap = np.load(\n",
    "        inverse_path.parent\n",
    "        / patient_path.replace(\n",
    "            \".jpg\", f\"{class_name}_{xai_method}_relevance.npy\"\n",
    "        )\n",
    "    )\n",
    "    negative_heatmap = (\n",
    "        torch.nn.functional.interpolate(\n",
    "            torch.tensor(negative_heatmap), size=image.shape, mode=\"bilinear\"\n",
    "        )\n",
    "        .detach()\n",
    "        .numpy()[0]\n",
    "    )\n",
    "    normal_heatmap = np.load(\n",
    "        save_folder\n",
    "        / f\"{model}\"\n",
    "        / training_type\n",
    "        / patient_path.replace(\n",
    "            \".jpg\", f\"{class_name}_{xai_method}_relevance.npy\"\n",
    "        )\n",
    "    )\n",
    "    normal_heatmap = (\n",
    "        torch.nn.functional.interpolate(\n",
    "            torch.tensor(normal_heatmap), size=image.shape, mode=\"bilinear\"\n",
    "        )\n",
    "        .detach()\n",
    "        .numpy()[0]\n",
    "    )\n",
    "    positive_heatmap = np.maximum(positive_heatmap, 0).sum(axis=0)\n",
    "    positive_heatmap = (positive_heatmap - positive_heatmap.min()) / (\n",
    "        positive_heatmap.max() - positive_heatmap.min()\n",
    "    )\n",
    "    negative_heatmap = np.maximum(negative_heatmap, 0).sum(axis=0)\n",
    "    negative_heatmap = (negative_heatmap - negative_heatmap.min()) / (\n",
    "        negative_heatmap.max() - negative_heatmap.min()\n",
    "    )\n",
    "    normal_heatmap = np.maximum(normal_heatmap, 0).sum(axis=0)\n",
    "    normal_heatmap = (normal_heatmap - normal_heatmap.min()) / (\n",
    "        normal_heatmap.max() - normal_heatmap.min()\n",
    "    )\n",
    "    if na_attribution_threshold:\n",
    "        positive_heatmap = np.where(\n",
    "            positive_heatmap < na_attribution_threshold, 0, 1\n",
    "        )\n",
    "        negative_heatmap = np.where(\n",
    "            negative_heatmap < na_attribution_threshold, 0, 1\n",
    "        )\n",
    "        normal_heatmap = np.where(\n",
    "            normal_heatmap < na_attribution_threshold, 0, 1\n",
    "        )\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(\n",
    "        positive_heatmap,\n",
    "        alpha=attribution_alpha,\n",
    "        cmap=attribution_cmap,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    plt.imshow(gt_mask, alpha=mask_alpha, cmap=mask_cmap)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder\n",
    "        / f\"aligned_heatmap_{training_type}_{model}_{class_name}_{xai_method}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(\n",
    "        positive_heatmap,\n",
    "        alpha=attribution_alpha,\n",
    "        cmap=attribution_cmap,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder\n",
    "        / f\"aligned_heatmap_{training_type}_{model}_{class_name}_{xai_method}_without_mask.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(gt_mask, alpha=mask_alpha, cmap=mask_cmap)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder / f\"gt_mask.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(\n",
    "        negative_heatmap,\n",
    "        alpha=attribution_alpha,\n",
    "        cmap=attribution_cmap,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    plt.imshow(gt_mask, alpha=mask_alpha, cmap=mask_cmap)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder\n",
    "        / f\"misaligned_heatmap_{training_type}_{model}_{class_name}_{xai_method}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.imshow(\n",
    "        negative_heatmap,\n",
    "        alpha=attribution_alpha,\n",
    "        cmap=attribution_cmap,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        images_save_folder\n",
    "        / f\"misaligned_heatmap_{training_type}_{model}_{class_name}_{xai_method}_without_mask.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution_cmap = ListedColormap([\"#FFFFFF00\", \"red\"])\n",
    "mask_cmap = ListedColormap([\"#FFFFFF00\", \"yellow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = [\n",
    "    571,\n",
    "    994,\n",
    "    758,\n",
    "]\n",
    "patients_name = [\n",
    "    \"upper_right\",\n",
    "    \"middle\",\n",
    "    \"lower_left\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient, patient_name in zip(patients, patients_name):\n",
    "    cur_data = diff_data.iloc[patient]\n",
    "    plot_binary_heatmap(\n",
    "        save_folder,\n",
    "        selected_model,\n",
    "        cur_data.pretraining,\n",
    "        cur_data.label,\n",
    "        selected_attribution,\n",
    "        patient_path=cur_data.path,\n",
    "        attribution_cmap=attribution_cmap,\n",
    "        mask_cmap=mask_cmap,\n",
    "        na_attribution_threshold=0.1,\n",
    "        mask_alpha=0.3,\n",
    "        images_save_folder=Path(f\"vit_ig/{patient_name}\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_data = diff_data.iloc[patients]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_data.to_csv(\"vit_ig/selected_patients.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CheXpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../dataset/train_split.csv\")\n",
    "val = pd.read_csv(\"../dataset/val_split.csv\")\n",
    "test = pd.read_csv(\"../dataset/test_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.concat([val, test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_renames = {\n",
    "    \"Enlarged Cardiomediastinum\": \"Enl. Card.\"\n",
    "}\n",
    "columns_names = {\n",
    "    0: \"Negative\",\n",
    "    1: \"Positive\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_counts(df, first_class_col):\n",
    "    df = df.loc[:, first_class_col:].fillna(0).replace(-1, 0).apply(\n",
    "        pd.Series.value_counts\n",
    "    ).T.sort_index().rename(index=classes_renames, columns=columns_names)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chexpert = get_val_counts(train, \"Enlarged Cardiomediastinum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_chexpert = get_val_counts(val, \"Enlarged Cardiomediastinum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CheXlocalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/chexlocalize/CheXpert/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_counts(df, first_class_col):\n",
    "    df = df.loc[:, first_class_col:].fillna(0).replace(-1, 0).apply(\n",
    "        pd.Series.value_counts\n",
    "    ).T.sort_index().rename(index=classes_renames, columns=columns_names)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_renames = {\n",
    "    \"Enlarged Cardiomediastinum\": \"Enl. Card.\"\n",
    "}\n",
    "columns_names = {\n",
    "    0: \"Negative\",\n",
    "    1: \"Positive\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chexlocalize = get_val_counts(df, \"No Finding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/chexlocalize/CheXpert/val_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_chexlocalize = get_val_counts(df, \"No Finding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.MultiIndex.from_product([[\"CheXpert\", \"CheXlocalize\"], [\"Train\", \"Test\"], [\"Negative\", \"Positive\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_chexpert = train_chexpert.join(val_chexpert, lsuffix='_train', rsuffix='_val')\n",
    "full_df_chexlocalize = test_chexlocalize.join(val_chexlocalize.fillna(0).astype(int), lsuffix='_test', rsuffix='_val')\n",
    "\n",
    "full_df = full_df_chexpert.join(full_df_chexlocalize, how=\"left\", lsuffix='_chexpert', rsuffix='_chexlocalize')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_chexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cols = full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.MultiIndex.from_product([[\"CheXpert\", \"CheXlocalize\"], [\"Train\", \"Test\"], [\"Negative\", \"Positive\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = pd.MultiIndex.from_tuples(\n",
    "    [\n",
    "        (\"Chexpert\", \"Training\", \"Negative\"),\n",
    "        (\"Chexpert\", \"Training\", \"Positive\"),\n",
    "        (\"Chexpert\", \"Validation\", \"Negative\"),\n",
    "        (\"Chexpert\", \"Validation\", \"Positive\"),\n",
    "        (\"CheXlocalize\", \"Fine-tuning\", \"Negative\"),\n",
    "        (\"CheXlocalize\", \"Fine-tuning\", \"Positive\"),\n",
    "        (\"CheXlocalize\", \"Validation\", \"Negative\"),\n",
    "        (\"CheXlocalize\", \"Validation\", \"Positive\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
